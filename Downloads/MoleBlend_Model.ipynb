{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qPgl0trz3ba"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'fairseq'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     FairseqEncoder,\n\u001b[0;32m      8\u001b[0m     FairseqEncoderModel,\n\u001b[0;32m      9\u001b[0m     register_model,\n\u001b[0;32m     10\u001b[0m     register_model_architecture,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     13\u001b[0m     LayerNorm, Fp32LayerNorm\n\u001b[0;32m     14\u001b[0m )\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fairseq'"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from fairseq import utils\n",
        "from fairseq.models import (\n",
        "    FairseqEncoder,\n",
        "    FairseqEncoderModel,\n",
        "    register_model,\n",
        "    register_model_architecture,\n",
        ")\n",
        "from fairseq.modules import (\n",
        "    LayerNorm, Fp32LayerNorm\n",
        ")\n",
        "from fairseq.utils import safe_hasattr\n",
        "\n",
        "from ..modules import (\n",
        "    init_params,\n",
        "    MoleBlendEncoder,\n",
        "    MoleBlendEncoderMolnet,\n",
        ")\n",
        "from typing import Optional\n",
        "\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhdjjwN3z-I8"
      },
      "outputs": [],
      "source": [
        "class RobertaClassificationHead(nn.Module):\n",
        "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, inner_dim, num_classes, activation_fn, pooler_dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(input_dim, inner_dim)\n",
        "        self.activation_fn = utils.get_activation_fn(activation_fn)\n",
        "        # self.ln = LayerNorm(inner_dim)\n",
        "        self.dropout = nn.Dropout(p=pooler_dropout)\n",
        "        self.out_proj = nn.Linear(inner_dim, num_classes)\n",
        "\n",
        "    def forward(self, features, **kwargs):\n",
        "        x = self.dropout(features)\n",
        "        x = self.dense(x)\n",
        "        x = self.activation_fn(x)\n",
        "        x = self.dropout(x)\n",
        "        # x = self.ln(x)\n",
        "        x = self.out_proj(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "@register_model(\"MoleBlend\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DysZzknu0CtG"
      },
      "outputs": [],
      "source": [
        "class MoleBlendModel(FairseqEncoderModel):\n",
        "    \"\"\"\n",
        "    Class for training a Masked Language Model. It also supports an\n",
        "    additional sentence level prediction if the sent-loss argument is set.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, args, encoder):\n",
        "        super().__init__(encoder)\n",
        "        self.args = args\n",
        "\n",
        "        # if specified then apply bert initialization on the model. We need\n",
        "        # to explictly call this to make sure that the output embeddings\n",
        "        # and projection layers are also correctly initialized\n",
        "        if getattr(args, \"apply_init\", False):\n",
        "            self.apply(init_params)\n",
        "        self.encoder_embed_dim = args.encoder_embed_dim\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def add_args(parser):\n",
        "        \"\"\"Add model-specific arguments to the parser.\"\"\"\n",
        "        parser.add_argument(\n",
        "            \"--pred-spd\", action=\"store_true\", default=False, help=\"add the shortest path distance prediction loss\",\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--stat\", action=\"store_true\", default=False, help=\"add the shortest path distance prediction loss\",\n",
        "        )\n",
        "\n",
        "        # Arguments related to dropout\n",
        "        parser.add_argument(\n",
        "            \"--mode-prob\", type=str, default=\"0.2,0.2,0.6\", help=\"probability of {2D+3D, 2D, 3D} mode for joint training\"\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--add-3d\", action='store_true', help=\"add 3D attention bias\"\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--no-2d\", action='store_true', help=\"remove 2D encodings\"\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--num-3d-bias-kernel\", type=int, default=128, metavar=\"D\", help=\"number of kernel in 3D attention bias\"\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--droppath-prob\", type=float, metavar=\"D\", help=\"stochastic path probability\", default=0.0\n",
        "        )\n",
        "\n",
        "        parser.add_argument(\n",
        "            \"--dropout\", type=float, metavar=\"D\", help=\"dropout probability\"\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--attention-dropout\",\n",
        "            type=float,\n",
        "            metavar=\"D\",\n",
        "            help=\"dropout probability for\" \" attention weights\",\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--act-dropout\",\n",
        "            type=float,\n",
        "            metavar=\"D\",\n",
        "            help=\"dropout probability after\" \" activation in FFN\",\n",
        "        )\n",
        "\n",
        "        # Arguments related to hidden states and self-attention\n",
        "        parser.add_argument(\n",
        "            \"--encoder-ffn-embed-dim\",\n",
        "            type=int,\n",
        "            metavar=\"N\",\n",
        "            help=\"encoder embedding dimension for FFN\",\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--encoder-layers\", type=int, metavar=\"N\", help=\"num encoder layers\"\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--encoder-attention-heads\",\n",
        "            type=int,\n",
        "            metavar=\"N\",\n",
        "            help=\"num encoder attention heads\",\n",
        "        )\n",
        "\n",
        "        # Arguments related to input and output embeddings\n",
        "        parser.add_argument(\n",
        "            \"--encoder-embed-dim\",\n",
        "            type=int,\n",
        "            metavar=\"N\",\n",
        "            help=\"encoder embedding dimension\",\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--share-encoder-input-output-embed\",\n",
        "            action=\"store_true\",\n",
        "            help=\"share encoder input\" \" and output embeddings\",\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--encoder-learned-pos\",\n",
        "            action=\"store_true\",\n",
        "            help=\"use learned positional embeddings in the encoder\",\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--no-token-positional-embeddings\",\n",
        "            action=\"store_true\",\n",
        "            help=\"if set, disables positional embeddings\" \" (outside self attention)\",\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--num-segment\", type=int, metavar=\"N\", help=\"num segment in the input\"\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--max-positions\", type=int, help=\"number of positional embeddings to learn\"\n",
        "        )\n",
        "\n",
        "        # Arguments related to sentence level prediction\n",
        "        parser.add_argument(\n",
        "            \"--sentence-class-num\",\n",
        "            type=int,\n",
        "            metavar=\"N\",\n",
        "            help=\"number of classes for sentence task\",\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--sent-loss\",\n",
        "            action=\"store_true\",\n",
        "            help=\"if set,\" \" calculate sentence level predictions\",\n",
        "        )\n",
        "\n",
        "        # Arguments related to parameter initialization\n",
        "        parser.add_argument(\n",
        "            \"--apply-init\",\n",
        "            action=\"store_true\",\n",
        "            help=\"use custom param initialization for MoleBlend\",\n",
        "        )\n",
        "\n",
        "        # misc params\n",
        "        parser.add_argument(\n",
        "            \"--activation-fn\",\n",
        "            choices=utils.get_available_activation_fns(),\n",
        "            help=\"activation function to use\",\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--pooler-activation-fn\",\n",
        "            choices=utils.get_available_activation_fns(),\n",
        "            help=\"Which activation function to use for pooler layer.\",\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--encoder-normalize-before\",\n",
        "            action=\"store_true\",\n",
        "            help=\"apply layernorm before each encoder block\",\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        parser.add_argument(\n",
        "            \"--blend-prob\", type=str, default=\"0.2,0.2,0.6\", help=\"ratio of spd, edge and 3d bias in mode blending\"\n",
        "        )\n",
        "\n",
        "        parser.add_argument(\n",
        "            \"--spd-num-classes\",\n",
        "            type=int,\n",
        "            default=11,\n",
        "            help=\"the output spd distance \",\n",
        "        )\n",
        "\n",
        "\n",
        "        parser.add_argument(\n",
        "            \"--edge-type-1-num-classes\",\n",
        "            type=int,\n",
        "            default=4,\n",
        "            help=\"the output edge type feature 1 num classes\"\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--edge-type-2-num-classes\",\n",
        "            type=int,\n",
        "            default=3,\n",
        "            help=\"the output edge type feature 2 num classes\"\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--edge-type-3-num-classes\",\n",
        "            type=int,\n",
        "            default=2,\n",
        "            help=\"the output edge type feature 2 num classes\"\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--blend-pred-3d-hidden-dim\",\n",
        "            type=int,\n",
        "            default=256,\n",
        "            help=\"the hidden dim for the 3d delta pos predict head\"\n",
        "        )\n",
        "\n",
        "\n",
        "        parser.add_argument(\n",
        "            \"--remove-head\",\n",
        "            action=\"store_true\",\n",
        "            default=False,\n",
        "            help=\"remove the original prediction head\"\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, src_tokens, segment_labels=None, **kwargs):\n",
        "        return self.encoder(src_tokens, segment_labels=segment_labels, **kwargs)\n",
        "\n",
        "    def max_positions(self):\n",
        "        return self.encoder.max_positions\n",
        "\n",
        "    @classmethod\n",
        "    def build_model(cls, args, task):\n",
        "        \"\"\"Build a new model instance.\"\"\"\n",
        "        # make sure all arguments are present in older models\n",
        "        base_architecture(args)\n",
        "\n",
        "        if not safe_hasattr(args, \"max_positions\"):\n",
        "            try:\n",
        "                args.max_positions = args.tokens_per_sample\n",
        "            except:\n",
        "                args.max_positions = args.max_nodes\n",
        "\n",
        "        logger.info(args)\n",
        "\n",
        "        if args.dataset_name.startswith(\"PCQM4M-LSC\"):\n",
        "            encoder = MoleBlend(args)\n",
        "        else:\n",
        "            args.num_classes = task.num_tasks\n",
        "            encoder = MoleBlendMolnet(args)\n",
        "\n",
        "        return cls(args, encoder)\n",
        "\n",
        "    def forward(self, batched_data, **kwargs):\n",
        "        return self.encoder(batched_data, **kwargs)  # input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7D3Odf9a0IZe"
      },
      "outputs": [],
      "source": [
        "class MoleBlend(FairseqEncoder):\n",
        "\n",
        "    def __init__(self, args):\n",
        "        super().__init__(dictionary=None)\n",
        "        self.max_positions = args.max_positions\n",
        "\n",
        "        blend_prob = self.get_blend_prob(args)\n",
        "\n",
        "\n",
        "        self.molecule_encoder = MoleBlendEncoder(\n",
        "            num_atoms=args.num_atoms,\n",
        "            num_in_degree=args.num_in_degree,\n",
        "            num_out_degree=args.num_out_degree,\n",
        "            num_edges=args.num_edges,\n",
        "            num_spatial=args.num_spatial,\n",
        "            num_edge_dis=args.num_edge_dis,\n",
        "            edge_type=args.edge_type,\n",
        "            multi_hop_max_dist=args.multi_hop_max_dist,\n",
        "            num_encoder_layers=args.encoder_layers,\n",
        "            embedding_dim=args.encoder_embed_dim,\n",
        "            ffn_embedding_dim=args.encoder_ffn_embed_dim,\n",
        "            num_attention_heads=args.encoder_attention_heads,\n",
        "            dropout=args.dropout,\n",
        "            attention_dropout=args.attention_dropout,\n",
        "            activation_dropout=args.act_dropout,\n",
        "            max_seq_len=self.max_positions,\n",
        "            num_segments=args.num_segment,\n",
        "            use_position_embeddings=not args.no_token_positional_embeddings,\n",
        "            encoder_normalize_before=args.encoder_normalize_before,\n",
        "            apply_init=args.apply_init,\n",
        "            activation_fn=args.activation_fn,\n",
        "            learned_pos_embedding=args.encoder_learned_pos,\n",
        "            sandwich_ln=args.sandwich_ln,\n",
        "            droppath_prob=args.droppath_prob,\n",
        "            add_3d=args.add_3d,\n",
        "            num_3d_bias_kernel=args.num_3d_bias_kernel,\n",
        "            no_2d=args.no_2d,\n",
        "            mode_prob=args.mode_prob,\n",
        "            regularization_3d_denosing=args.regularization_3d_denosing,\n",
        "            blending=args.blending,\n",
        "            blend_prob=blend_prob,\n",
        "            blend_pred_spd=args.blend_pred_spd,\n",
        "            blend_pred_edge=args.blend_pred_edge,\n",
        "            blend_pred_3d=args.blend_pred_3d,\n",
        "            spd_num_classes=args.spd_num_classes,\n",
        "            edge_type_1_num_classes=args.edge_type_1_num_classes,\n",
        "            edge_type_2_num_classes=args.edge_type_2_num_classes,\n",
        "            edge_type_3_num_classes=args.edge_type_3_num_classes,\n",
        "            edge_max_dist=args.edge_max_dist,\n",
        "            blend_pred_3d_hidden_dim=args.blend_pred_3d_hidden_dim,\n",
        "        )\n",
        "\n",
        "        self.embed_out = None\n",
        "        self.proj_out = None\n",
        "\n",
        "        self.lm_head_transform_weight = nn.Linear(\n",
        "            args.encoder_embed_dim, args.encoder_embed_dim\n",
        "        )\n",
        "        self.activation_fn = utils.get_activation_fn(args.activation_fn)\n",
        "        self.layer_norm = Fp32LayerNorm(args.encoder_embed_dim)  # LayerNorm(args.encoder_embed_dim)\n",
        "\n",
        "        self.remove_head = args.remove_head\n",
        "        if not args.remove_head:\n",
        "            self.lm_output_learned_bias = nn.Parameter(torch.zeros(1))\n",
        "            self.embed_out = nn.Linear(\n",
        "                args.encoder_embed_dim, 1, bias=False\n",
        "            )\n",
        "        else:\n",
        "            if isinstance(args.num_classes, int):\n",
        "                self.proj_out = RobertaClassificationHead(\n",
        "                    args.encoder_embed_dim, args.encoder_embed_dim, args.num_classes, args.activation_fn\n",
        "                )\n",
        "\n",
        "\n",
        "    def forward(self, batched_data, perturb=None, segment_labels=None, masked_tokens=None, **unused):\n",
        "\n",
        "        inner_states, atom_output, blend_spd_pred_logits, blend_edge_pred_logits, blend_3d_pred_logits, blend_mask_spd, blend_mask_edge, blend_mask_3d, blend_mask_2d_feature, blend_mask_3d_feature = self.molecule_encoder(\n",
        "            batched_data,\n",
        "            segment_labels=segment_labels,\n",
        "            perturb=perturb,\n",
        "        )\n",
        "        # atom_output: [B, n_atom, 3]\n",
        "        x = inner_states[-1].transpose(0, 1)  # [B, n_atom+1, C]\n",
        "\n",
        "        if not self.remove_head:\n",
        "            x = self.layer_norm(self.activation_fn(self.lm_head_transform_weight(x)))\n",
        "            x = self.embed_out(x)  # [B, n_atom+1, 1]\n",
        "            x = x + self.lm_output_learned_bias\n",
        "        else:\n",
        "            x = self.proj_out(x)\n",
        "\n",
        "        return x, atom_output, blend_spd_pred_logits, blend_edge_pred_logits, blend_3d_pred_logits, blend_mask_3d_feature, {\n",
        "            \"inner_states\": inner_states,\n",
        "        }\n",
        "\n",
        "    def max_positions(self):\n",
        "        \"\"\"Maximum output length supported by the encoder.\"\"\"\n",
        "        return self.max_positions\n",
        "\n",
        "    def upgrade_state_dict_named(self, state_dict, name):\n",
        "        return state_dict\n",
        "\n",
        "    def get_blend_prob(self, args):\n",
        "        blend_prob = None\n",
        "        if args.blending:\n",
        "            try:\n",
        "                blend_prob = [float(item) for item in args.blend_prob.split(',')]\n",
        "                assert len(blend_prob) == 3\n",
        "                assert sum(blend_prob) == 1\n",
        "            except:\n",
        "                blend_prob = [0.2, 0.2, 0.6]\n",
        "\n",
        "        return blend_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ub91Yclk0Lqp"
      },
      "outputs": [],
      "source": [
        "class MoleBlendMolnet(FairseqEncoder):\n",
        "\n",
        "    def __init__(self, args):\n",
        "        super().__init__(dictionary=None)\n",
        "        self.max_positions = args.max_positions\n",
        "\n",
        "        self.molecule_encoder = MoleBlendEncoderMolnet(\n",
        "            num_atoms=args.num_atoms,\n",
        "            num_in_degree=args.num_in_degree,\n",
        "            num_out_degree=args.num_out_degree,\n",
        "            num_edges=args.num_edges,\n",
        "            num_spatial=args.num_spatial,\n",
        "            num_edge_dis=args.num_edge_dis,\n",
        "            edge_type=args.edge_type,\n",
        "            multi_hop_max_dist=args.multi_hop_max_dist,\n",
        "            num_encoder_layers=args.encoder_layers,\n",
        "            embedding_dim=args.encoder_embed_dim,\n",
        "            ffn_embedding_dim=args.encoder_ffn_embed_dim,\n",
        "            num_attention_heads=args.encoder_attention_heads,\n",
        "            dropout=args.dropout,\n",
        "            attention_dropout=args.attention_dropout,\n",
        "            activation_dropout=args.act_dropout,\n",
        "            max_seq_len=self.max_positions,\n",
        "            num_segments=args.num_segment,\n",
        "            use_position_embeddings=not args.no_token_positional_embeddings,\n",
        "            encoder_normalize_before=args.encoder_normalize_before,\n",
        "            apply_init=args.apply_init,\n",
        "            activation_fn=args.activation_fn,\n",
        "            learned_pos_embedding=args.encoder_learned_pos,\n",
        "            sandwich_ln=args.sandwich_ln,\n",
        "            droppath_prob=args.droppath_prob,\n",
        "            add_3d=args.add_3d,\n",
        "            num_3d_bias_kernel=args.num_3d_bias_kernel,\n",
        "            no_2d=args.no_2d,\n",
        "            mode_prob=args.mode_prob,\n",
        "        )\n",
        "\n",
        "\n",
        "        self.embed_out = None\n",
        "        self.proj_out = None\n",
        "\n",
        "        # remove_head is set to true during fine-tuning\n",
        "        self.load_softmax = not getattr(args, \"remove_head\", False)\n",
        "\n",
        "        self.lm_head_transform_weight = nn.Linear(\n",
        "            args.encoder_embed_dim, args.encoder_embed_dim\n",
        "        )\n",
        "        self.activation_fn = utils.get_activation_fn(args.activation_fn)\n",
        "        self.layer_norm = LayerNorm(args.encoder_embed_dim)\n",
        "\n",
        "        if self.load_softmax:\n",
        "            self.lm_output_learned_bias = nn.Parameter(torch.zeros(1))\n",
        "            self.embed_out = nn.Linear(\n",
        "                args.encoder_embed_dim, 1, bias=False\n",
        "            )\n",
        "        else:\n",
        "            self.proj_out = RobertaClassificationHead(\n",
        "                    args.encoder_embed_dim, args.encoder_embed_dim, args.num_classes, args.activation_fn\n",
        "                )\n",
        "\n",
        "\n",
        "    def forward(self, batched_data, perturb=None, segment_labels=None, masked_tokens=None, **unused):\n",
        "\n",
        "        inner_states, atom_output = self.molecule_encoder(\n",
        "            batched_data,\n",
        "            segment_labels=segment_labels,\n",
        "            perturb=perturb,\n",
        "        )\n",
        "\n",
        "        x = inner_states[-1].transpose(0, 1)\n",
        "\n",
        "        if self.load_softmax:\n",
        "            x = self.layer_norm(self.activation_fn(self.lm_head_transform_weight(x)))\n",
        "            x = self.embed_out(x)\n",
        "            x = x + self.lm_output_learned_bias\n",
        "        else:\n",
        "            x = self.proj_out(x)\n",
        "\n",
        "        return x, atom_output, {\n",
        "            \"inner_states\": inner_states,\n",
        "        }\n",
        "\n",
        "    def max_positions(self):\n",
        "        \"\"\"Maximum output length supported by the encoder.\"\"\"\n",
        "        return self.max_positions\n",
        "\n",
        "    def upgrade_state_dict_named(self, state_dict, name):\n",
        "        tmp_dict = {}\n",
        "        if not self.load_softmax:\n",
        "            for k in list(state_dict.keys()):\n",
        "                if (\n",
        "                    \"embed_out.weight\" in k\n",
        "                    or \"sentence_projection_layer.weight\" in k\n",
        "                    or \"lm_output_learned_bias\" in k\n",
        "                    or \"node_proc\" in k\n",
        "                    or \"proj_out.ln\" in k\n",
        "                    or \"atom_proc\" in k\n",
        "                    # or \"emb_layer_norm\" in k\n",
        "                    or \"blend_\" in k\n",
        "                ):\n",
        "                    print(\"Removing\", k, \"(because load_softmax is False)\")\n",
        "                    tmp_dict[k] = state_dict[k]\n",
        "                    del state_dict[k]\n",
        "\n",
        "            may_missing_keys = [\n",
        "                'encoder.proj_out.dense.weight',\n",
        "                'encoder.proj_out.dense.bias',\n",
        "                'encoder.proj_out.out_proj.weight',\n",
        "                'encoder.proj_out.out_proj.bias',\n",
        "                'encoder.lm_head_transform_weight.weight',\n",
        "                'encoder.lm_head_transform_weight.bias',\n",
        "                'encoder.layer_norm.weight',\n",
        "                'encoder.layer_norm.bias',]\n",
        "\n",
        "            named_parameters = {\n",
        "                \"encoder.\" + k: v\n",
        "                for k, v in self.named_parameters()\n",
        "            }\n",
        "\n",
        "            for k in may_missing_keys:\n",
        "                if k not in state_dict.keys():\n",
        "                    state_dict[k] = named_parameters[k].data\n",
        "                    print(\"Copying\", k, \"(from model initialization)\")\n",
        "        return state_dict\n",
        "\n",
        "\n",
        "\n",
        "@register_model_architecture(\"MoleBlend\", \"moleblend\")\n",
        "def base_architecture(args):\n",
        "    args.dropout = getattr(args, \"dropout\", 0.1)\n",
        "    args.attention_dropout = getattr(args, \"attention_dropout\", 0.1)\n",
        "    args.act_dropout = getattr(args, \"act_dropout\", 0.0)\n",
        "\n",
        "    args.encoder_ffn_embed_dim = getattr(args, \"encoder_ffn_embed_dim\", 4096)\n",
        "    args.encoder_layers = getattr(args, \"encoder_layers\", 6)\n",
        "    args.encoder_attention_heads = getattr(args, \"encoder_attention_heads\", 8)\n",
        "\n",
        "    args.encoder_embed_dim = getattr(args, \"encoder_embed_dim\", 1024)\n",
        "    args.share_encoder_input_output_embed = getattr(\n",
        "        args, \"share_encoder_input_output_embed\", False\n",
        "    )\n",
        "    args.encoder_learned_pos = getattr(args, \"encoder_learned_pos\", False)\n",
        "    args.no_token_positional_embeddings = getattr(\n",
        "        args, \"no_token_positional_embeddings\", False\n",
        "    )\n",
        "    args.num_segment = getattr(args, \"num_segment\", 2)\n",
        "\n",
        "    args.sentence_class_num = getattr(args, \"sentence_class_num\", 2)\n",
        "    args.sent_loss = getattr(args, \"sent_loss\", False)\n",
        "\n",
        "    args.apply_init = getattr(args, \"apply_init\", False)\n",
        "\n",
        "    args.activation_fn = getattr(args, \"activation_fn\", \"relu\")\n",
        "    args.pooler_activation_fn = getattr(args, \"pooler_activation_fn\", \"tanh\")\n",
        "    args.encoder_normalize_before = getattr(args, \"encoder_normalize_before\", False)\n",
        "\n",
        "    args.sandwich_ln = getattr(args, \"sandwich_ln\", False)\n",
        "    args.droppath_prob = getattr(args, \"droppath_prob\", 0.0)\n",
        "\n",
        "    args.no_2d = getattr(args, \"no_2d\", False)\n",
        "\n",
        "    # args.pred_energy = getattr(args, \"pred_energy\", False)\n",
        "    args.blend_prob = getattr(args, \"blend_prob\", \"0.2,0.2,0.6\")\n",
        "\n",
        "    args.spd_num_classes = getattr(args, \"spd_num_classes\", 11)\n",
        "    args.blend_pred_3d_hidden_dim = getattr(args, \"blend_pred_3d_hidden_dim\", 256)\n",
        "    args.edge_max_dist = getattr(args, \"edge_max_dist\", 5)\n",
        "\n",
        "\n",
        "\n",
        "@register_model_architecture(\"MoleBlend\", \"moleblend_base\")\n",
        "def bert_base_architecture(args):\n",
        "    args.encoder_embed_dim = getattr(args, \"encoder_embed_dim\", 768)\n",
        "    args.share_encoder_input_output_embed = getattr(\n",
        "        args, \"share_encoder_input_output_embed\", False\n",
        "    )\n",
        "    args.no_token_positional_embeddings = getattr(\n",
        "        args, \"no_token_positional_embeddings\", False\n",
        "    )\n",
        "    args.encoder_learned_pos = getattr(args, \"encoder_learned_pos\", True)\n",
        "    args.num_segment = getattr(args, \"num_segment\", 2)\n",
        "\n",
        "    args.encoder_layers = getattr(args, \"encoder_layers\", 12)\n",
        "\n",
        "    args.encoder_attention_heads = getattr(args, \"encoder_attention_heads\", 32)\n",
        "    args.encoder_ffn_embed_dim = getattr(args, \"encoder_ffn_embed_dim\", 768)\n",
        "\n",
        "    args.sentence_class_num = getattr(args, \"sentence_class_num\", 2)\n",
        "    args.sent_loss = getattr(args, \"sent_loss\", False)\n",
        "\n",
        "    args.apply_init = getattr(args, \"apply_init\", True)\n",
        "\n",
        "    args.activation_fn = getattr(args, \"activation_fn\", \"gelu\")\n",
        "    args.pooler_activation_fn = getattr(args, \"pooler_activation_fn\", \"tanh\")\n",
        "    args.encoder_normalize_before = getattr(args, \"encoder_normalize_before\", True)\n",
        "    args.sandwich_ln = getattr(args, \"sandwich_ln\", False)\n",
        "    args.droppath_prob = getattr(args, \"droppath_prob\", 0.0)\n",
        "\n",
        "    args.add_3d = getattr(args, \"add_3d\", False)\n",
        "    args.num_3d_bias_kernel = getattr(args, \"num_3d_bias_kernel\", 128)\n",
        "    args.no_2d = getattr(args, \"no_2d\", False)\n",
        "    args.mode_prob = getattr(args, \"mode_prob\", \"0.2,0.2,0.6\")\n",
        "    # args.pred_spd = getattr(args, \"pred_spd\", False)\n",
        "    base_architecture(args)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
